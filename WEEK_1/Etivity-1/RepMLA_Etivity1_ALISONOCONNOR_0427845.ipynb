{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvexyww7a-0o"
   },
   "source": [
    "<div>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
    "</div> \n",
    "\n",
    "#**Artificial Intelligence - MSc**\n",
    "CS6501 - MACHINE LEARNING AND APPLICATIONS\n",
    "#**Business Analytics - MSc**\n",
    "ET5003 - MACHINE LEARNING APPLICATIONS \n",
    "##***Annual Repeat***\n",
    "###Instructor: Enrique Naredo\n",
    "\n",
    "###RepMLA_Lab-1.13\n",
    "\n",
    "Student ID: 0427845\n",
    "\n",
    "Student name: Alison O'Connor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLNHPNlXlUk0"
   },
   "source": [
    "# E-tivity: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbGmVVOWlUk3"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The goal is to implement the K-nearest neighbors algorithm (a supervised machine learning algorithm) and apply it to a real dataset. Along the way you should familiarize yourself with some of the terminology you have read in the note. You will also get a chance to practice with Python and working with large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TpgU67FlUk3"
   },
   "source": [
    "## Dataset introduction\n",
    "\n",
    "The handwritten digit recognition is the ability of computers to recognize human handwritten digits. It is a hard task for the machine because handwritten digits are not perfect and can be made with many different flavors. The handwritten digit recognition is the solution to this problem which uses the image of a digit and recognizes the digit present in the image.\n",
    "\n",
    "The dataset for this E-tivity is a set of handwritten digits from zip codes written on hand-addressed letters (MNIST-Modified National Institute of Standards and Technology database). \n",
    "\n",
    "Read about this dataset by going to the Elements of Statistical Learning website, <a href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">ESL</a>, then clicking on the `Data` tab, then clicking on the `Info` for the zip code dataset (the last dataset). \n",
    "\n",
    "Use the command less in the terminal to view the beginning of each file. Both datasets have the same format: the first column is the \"label\" (or class) (here an integer between 0 and 9, inclusive, that corresponds to the identity of a hand-written zip code digit), and the rest of each row is made up of gray-scale values corresponding to the image of this hand-written digit.\n",
    "\n",
    "One useful technique is to load a dataset from a file into a numpy array. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fWOGDvcolUk4",
    "outputId": "f961bf17-07e8-49dc-a9fc-32c9cc220d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 257)\n",
      "(2007, 257)\n"
     ]
    }
   ],
   "source": [
    "##CHECK CURRENT WORK DIRECTORY.\n",
    "cwd=os.getcwd()\n",
    "\n",
    "train_data = np.loadtxt(\"mnist.train\") #\"path/to/train/file\"\n",
    "test_data  = np.loadtxt(\"mnist.test\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_--pMIHJlUk5",
    "outputId": "f738db1f-27d8-460a-fe9a-e82dd96c441a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.   , -1.   , -1.   , ..., -1.   , -1.   , -1.   ],\n",
       "       [ 5.   , -1.   , -1.   , ..., -0.671, -0.828, -1.   ],\n",
       "       [ 4.   , -1.   , -1.   , ..., -1.   , -1.   , -1.   ],\n",
       "       ...,\n",
       "       [ 3.   , -1.   , -1.   , ..., -1.   , -1.   , -1.   ],\n",
       "       [ 0.   , -1.   , -1.   , ..., -1.   , -1.   , -1.   ],\n",
       "       [ 1.   , -1.   , -1.   , ..., -1.   , -1.   , -1.   ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data #each row is a different image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "336Q8CIUlUk6"
   },
   "source": [
    "The first column is the class, it tells us which digit we will find in the image, as you can see hereafter for the first row (it is a 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UyPvWvnzlUk6",
    "outputId": "844b1f57-b4f1-4d07-bdce-8e0deb5eed0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.    -1.    -1.    -1.    -1.    -1.    -1.    -0.631  0.862 -0.167\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.    -1.    -1.    -0.992  0.297  1.     0.307\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.    -1.    -1.    -0.41   1.     0.986 -0.565\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.    -1.    -0.683  0.825  1.     0.562 -1.\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.    -0.938  0.54   1.     0.778 -0.715 -1.\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.     0.1    1.     0.922 -0.439 -1.    -1.\n",
      "  -1.    -1.    -1.    -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -0.257  0.95   1.    -0.162 -1.    -1.    -1.\n",
      "  -0.987 -0.714 -0.832 -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -0.797  0.909  1.     0.3   -0.961 -1.    -1.    -0.55\n",
      "   0.485  0.996  0.867  0.092 -1.    -1.   ]\n",
      " [-1.    -1.     0.278  1.     0.877 -0.824 -1.    -0.905  0.145  0.977\n",
      "   1.     1.     1.     0.99  -0.745 -1.   ]\n",
      " [-1.    -0.95   0.847  1.     0.327 -1.    -1.     0.355  1.     0.655\n",
      "  -0.109 -0.185  1.     0.988 -0.723 -1.   ]\n",
      " [-1.    -0.63   1.     1.     0.068 -0.925  0.113  0.96   0.308 -0.884\n",
      "  -1.    -0.075  1.     0.641 -0.995 -1.   ]\n",
      " [-1.    -0.677  1.     1.     0.753  0.341  1.     0.707 -0.942 -1.\n",
      "  -1.     0.545  1.     0.027 -1.    -1.   ]\n",
      " [-1.    -0.903  0.792  1.     1.     1.     1.     0.536  0.184  0.812\n",
      "   0.837  0.978  0.864 -0.63  -1.    -1.   ]\n",
      " [-1.    -1.    -0.452  0.828  1.     1.     1.     1.     1.     1.\n",
      "   1.     1.     0.135 -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -0.483  0.813  1.     1.     1.     1.     1.\n",
      "   1.     0.219 -0.943 -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    -1.    -0.974 -0.429  0.304  0.823  1.     0.482\n",
      "  -0.474 -0.991 -1.    -1.    -1.    -1.   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c4547b6340>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "row=0\n",
    "flatten_image=train_data[row,1:]# each 16x16 image has been flatten into a vector\n",
    "im=flatten_image.reshape(16,16)\n",
    "print(im)#as a matrix\n",
    "plt.gray()\n",
    "plt.imshow(im)#as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AktYMkHQlUk7"
   },
   "source": [
    "The test set is similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rIn2eSfSlUk7",
    "outputId": "2989e2e3-54ab-492a-e071-25cbd7c0c4bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., -1., -1., ..., -1., -1., -1.],\n",
       "       [ 6., -1., -1., ..., -1., -1., -1.],\n",
       "       [ 3., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 4., -1., -1., ..., -1., -1., -1.],\n",
       "       [ 0., -1., -1., ..., -1., -1., -1.],\n",
       "       [ 1., -1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ3I2AgxlUk7"
   },
   "source": [
    "## Step 2: Filter the Data\n",
    "To start, we will just consider two classes, but here we have 10. We will get to such problems later, but for now, devise a way to retain only the rows which have label 2 or 3. Do this for both the train and test data.\n",
    "\n",
    "One important note: it may be convenient to relabel the 2 to -1 and the 3 to +1, since this will work better with our methods later on (but you do not have to do this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    -1.    -1.    ... -1.    -1.    -1.   ]\n",
      " [-1.    -1.    -1.    ... -0.983 -1.    -1.   ]\n",
      " [-1.    -1.    -1.    ...  1.    -0.445 -1.   ]\n",
      " ...\n",
      " [ 1.    -1.    -1.    ...  0.239 -0.499 -1.   ]\n",
      " [-1.    -1.    -1.    ... -0.804  0.189  0.068]\n",
      " [-1.    -1.    -1.    ... -1.    -1.    -1.   ]]\n"
     ]
    }
   ],
   "source": [
    "#FILTER THE TRAINING DATA\n",
    "sub_train=train_data[(train_data[:,0]<=3) & (train_data[:,0]>=2)]\n",
    "# print(sub_train[100:150])\n",
    "##REPLACE ALL VALUES IN FIRST COLUMN 3=1 AND 2=-1\n",
    "##Run np where on first column of sub_train (returns 1D array same num of items as rows of sub_train)\n",
    "a=np.where(sub_train[:,0]==3, 1, -1)\n",
    "##replace first column of subtrain with new array\n",
    "sub_train[:,0]=a\n",
    "print(sub_train[100:120])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER THE TEST DATA\n",
    "sub_test=test_data[(test_data[:,0]<=3) & (test_data[:,0]>=2)]\n",
    "# print(sub_test[200:250])\n",
    "a=np.where(sub_test[:,0]==3, 1, -1) #CREATE THE REPLACEMENT ARRAY\n",
    "sub_test[:,0]=a\n",
    "# print(sub_test[200:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPNOPCNrlUk8"
   },
   "source": [
    "## Implement K-nearest neighbors\n",
    "\n",
    "The main goal of the E-tivity is to implement the K-nearest neighbors classifier to predict the class of each example from the test dataset. Exactly how you implement this part is up to you, but your code should be decomposed into functions, well commented, and easy to understand. Here are some suggestions:\n",
    "\n",
    "**Classification**\n",
    "Create a function that takes as input the train set, (at least) a test example and an integer K, and outputs a prediction based on a nearest-neighbor classifier. This function will loop through all the training examples, find the distance between each one and the input test example, and then find the K nearest neighbors (you are welcome to use numpy sorting methods, but look up how they work first). For this subroutine, we will need a distance function. In practice, you have to implement the algorithm 3 in <a href=\"http://ciml.info/dl/v0_99/ciml-v0_99-ch03.pdf\">Duame</a> (pag. 33).\n",
    "\n",
    "\n",
    "You should implement a Python function like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0UOu4rRklUk8"
   },
   "outputs": [],
   "source": [
    "def KNN(train,test,K):\n",
    "    ##USE SKLEARN TO RUN KMEANS FOR A NUMBER OF K CLUSTERS\n",
    "    clustered_data=cluster.KMeans(n_clusters=K, n_init=10, max_iter=300).fit(test)\n",
    "    \n",
    "    return clustered_data.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red < I'm confused. The first item in each row of our arrays is the known class of the image. So if we run KMeans on the data as it currently is then the Euclidean distance will always find the 'nearest neighbour' to be the correct class because the class is in the array. Should we only be using this part of the array [:, 1:end]? /font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>0.442</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.345</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.811</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.755</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.882</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.749</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.325</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>-0.985</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.726</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.555</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.416</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.968</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.933</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1389 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0    -1.000 -1.000 -1.000 -1.000 -1.000 -0.928 -0.204  0.751  0.466  0.234   \n",
       "1    -1.000 -1.000 -1.000 -0.830  0.442  1.000  1.000  0.479 -0.328 -0.947   \n",
       "2    -1.000 -1.000 -1.000 -1.000 -1.000 -0.104  0.549  0.579  0.579  0.857   \n",
       "3    -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.107  1.000  1.000  0.877   \n",
       "4    -1.000 -1.000 -1.000 -1.000 -0.674  0.492  0.573  0.755 -0.018 -0.290   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1384 -1.000 -0.882 -0.334  0.267  0.333  0.749  1.000  1.000  1.000  1.000   \n",
       "1385 -0.985 -0.048  0.226  0.226  0.226 -0.355 -0.807 -1.000 -0.726 -0.555   \n",
       "1386 -1.000 -1.000 -1.000 -0.988 -0.527 -0.208  0.620  1.000  0.467  0.396   \n",
       "1387 -1.000 -1.000 -1.000 -0.990  0.708  0.557  0.347 -0.107 -0.758 -0.975   \n",
       "1388 -1.000 -1.000 -1.000 -0.783 -0.984 -0.827  0.068  1.000  1.000  1.000   \n",
       "\n",
       "      ...    247    248    249    250    251    252    253  254  255  TARGET  \n",
       "0     ...  0.639  1.000  1.000  0.791  0.439 -0.199 -0.883 -1.0 -1.0     1.0  \n",
       "1     ...  0.671  0.345 -0.507 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "2     ...  0.579  0.811  1.000  1.000  0.715  0.107 -0.526 -1.0 -1.0     1.0  \n",
       "3     ...  0.322  0.813  1.000  1.000  0.633 -0.144 -0.994 -1.0 -1.0     1.0  \n",
       "4     ...  1.000  1.000  0.689 -0.530 -1.000 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...  ...  ...     ...  \n",
       "1384  ...  1.000  1.000  1.000  0.809  0.325 -0.820 -1.000 -1.0 -1.0     1.0  \n",
       "1385  ... -0.555 -0.555 -0.555 -0.556 -1.000 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "1386  ...  0.899  0.416 -0.510 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "1387  ...  0.636  0.167 -0.968 -1.000 -1.000 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "1388  ...  1.000  1.000  0.727 -0.342 -0.933 -1.000 -1.000 -1.0 -1.0     1.0  \n",
       "\n",
       "[1389 rows x 257 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##SEPARATE ARRAYS IN TO X (FEATURE) AND Y(TARGET)\n",
    "train_X, train_y = sub_train[:, 1:], sub_train[:, 0]\n",
    "test_X, test_y = sub_test[:, 1:], sub_test[:, 0]\n",
    "\n",
    "##Create df where 'y' targets are index\n",
    "train_df=pd.DataFrame(train_X)\n",
    "train_df['TARGET']=train_y\n",
    "\n",
    "test_df=pd.DataFrame(test_X)\n",
    "test_df['TARGET']=test_y\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -0.043985\n",
       "1        -0.055211\n",
       "2        -0.015202\n",
       "3         0.070526\n",
       "4         0.139937\n",
       "            ...   \n",
       "252      -0.101586\n",
       "253      -0.232079\n",
       "254      -0.237160\n",
       "255      -0.171841\n",
       "TARGET    1.000000\n",
       "Name: TARGET, Length: 257, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix=train_df.corr()\n",
    "corr_matrix['TARGET']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FOR A NUMBER OF K CLUSTERS \n",
    "##EVERY ROW OF THE TEST SET SHOULD BE PUT THROUGH THE ALGORITHM\n",
    "##\n",
    "\n",
    "k_list=[1, 2, 5, 10]\n",
    "labels={}\n",
    "\n",
    "# ##FOR SET NUMBER OF CLUSTERS\n",
    "# for K in k_list:\n",
    "#     ##APPEND THE NUM CLUSTERS AND LABELS TO LABELS DICTIONARY\n",
    "#     labels[K]=KNN(sub_train, sub_test, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 2: array([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]),\n",
       " 5: array([0, 3, 0, 2, 3, 4, 3, 0, 0, 4, 0, 4, 3, 1, 3, 0, 4, 1, 1, 3, 3, 4,\n",
       "        2, 1, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 2, 0, 3, 0, 2, 4, 0, 1, 2, 3,\n",
       "        3, 4, 1, 0, 3, 2, 2, 0, 3, 3, 0, 4, 2, 1, 1, 2, 2, 2, 3, 3, 4, 2,\n",
       "        2, 0, 2, 4, 3, 1, 4, 0, 2, 1, 4, 4, 4, 2, 3, 2, 0, 2, 3, 4, 0, 2,\n",
       "        0, 2, 2, 1, 4, 0, 4, 2, 3, 0, 1, 3, 2, 3, 2, 4, 0, 4, 3, 0, 1, 3,\n",
       "        1, 1, 0, 1, 2, 3, 4, 1, 1, 4, 0, 3, 0, 1, 3, 3, 0, 2, 2, 0, 0, 4,\n",
       "        1, 4, 1, 3, 0, 0, 2, 2, 2, 2, 0, 0, 1, 2, 2, 3, 0, 2, 1, 4, 2, 0,\n",
       "        0, 1, 2, 1, 3, 1, 1, 1, 0, 1, 4, 0, 2, 0, 2, 1, 1, 0, 3, 0, 3, 1,\n",
       "        1, 4, 4, 1, 0, 0, 2, 3, 0, 4, 1, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2,\n",
       "        2, 2, 2, 0, 2, 2, 2, 4, 4, 1, 0, 4, 1, 3, 3, 4, 0, 2, 4, 4, 2, 1,\n",
       "        0, 1, 4, 0, 2, 2, 3, 2, 4, 4, 2, 0, 2, 1, 4, 1, 2, 1, 1, 1, 1, 0,\n",
       "        2, 3, 2, 3, 1, 0, 1, 0, 1, 3, 2, 2, 0, 1, 0, 0, 3, 2, 2, 0, 0, 2,\n",
       "        4, 2, 2, 2, 2, 0, 1, 2, 0, 2, 2, 4, 1, 3, 0, 2, 1, 4, 2, 0, 1, 4,\n",
       "        1, 2, 2, 0, 0, 4, 4, 3, 3, 3, 3, 3, 1, 3, 2, 2, 1, 1, 4, 4, 4, 4,\n",
       "        2, 4, 4, 0, 4, 3, 3, 0, 3, 3, 0, 0, 0, 4, 1, 1, 0, 2, 2, 2, 0, 2,\n",
       "        3, 4, 1, 2, 1, 1, 0, 4, 4, 3, 4, 4, 2, 0, 2, 0, 4, 4, 4, 0, 3, 1,\n",
       "        2, 2, 3, 1, 1, 2, 2, 0, 4, 0, 3, 2]),\n",
       " 10: array([5, 2, 0, 6, 4, 4, 4, 7, 0, 3, 8, 2, 2, 2, 4, 0, 2, 1, 1, 4, 4, 3,\n",
       "        6, 2, 7, 0, 2, 8, 8, 8, 4, 4, 3, 4, 5, 5, 4, 5, 5, 3, 8, 4, 6, 4,\n",
       "        4, 3, 1, 7, 2, 6, 9, 7, 4, 2, 7, 2, 5, 1, 1, 6, 3, 5, 4, 4, 4, 9,\n",
       "        0, 0, 6, 3, 4, 2, 2, 8, 6, 1, 3, 3, 3, 0, 2, 9, 0, 9, 2, 2, 0, 5,\n",
       "        0, 6, 0, 1, 2, 7, 2, 5, 4, 9, 1, 2, 6, 2, 5, 3, 7, 3, 2, 5, 2, 4,\n",
       "        1, 1, 0, 3, 6, 4, 3, 1, 2, 2, 8, 4, 8, 1, 4, 4, 0, 9, 9, 5, 8, 3,\n",
       "        2, 2, 2, 4, 0, 8, 5, 5, 9, 6, 8, 7, 2, 6, 6, 6, 8, 9, 1, 2, 9, 8,\n",
       "        7, 2, 5, 1, 4, 1, 1, 2, 8, 1, 3, 7, 5, 5, 5, 2, 1, 8, 4, 8, 4, 1,\n",
       "        2, 3, 3, 1, 7, 7, 9, 4, 8, 3, 2, 6, 5, 5, 9, 6, 6, 0, 9, 7, 1, 9,\n",
       "        9, 9, 9, 7, 5, 6, 6, 4, 2, 1, 5, 3, 1, 4, 2, 3, 0, 5, 2, 2, 5, 2,\n",
       "        0, 1, 2, 8, 6, 9, 4, 5, 3, 3, 6, 0, 5, 1, 2, 1, 9, 1, 2, 1, 1, 7,\n",
       "        9, 2, 9, 4, 1, 8, 1, 0, 1, 4, 9, 9, 0, 1, 7, 7, 4, 5, 9, 0, 8, 9,\n",
       "        3, 6, 5, 6, 5, 0, 1, 9, 9, 5, 5, 3, 1, 4, 5, 5, 1, 3, 6, 7, 1, 2,\n",
       "        1, 6, 6, 0, 7, 4, 3, 4, 4, 4, 4, 4, 1, 6, 6, 6, 1, 1, 2, 3, 2, 3,\n",
       "        6, 2, 2, 7, 2, 4, 4, 7, 4, 4, 9, 8, 7, 2, 1, 1, 8, 6, 6, 6, 7, 6,\n",
       "        2, 3, 1, 5, 1, 1, 7, 3, 3, 4, 3, 3, 5, 0, 5, 7, 2, 2, 2, 7, 4, 1,\n",
       "        6, 6, 4, 1, 1, 6, 6, 8, 2, 7, 4, 5])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##I HAVE NO IDEA WHAT THESE ARRAYS MEAN. \n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIKGEbjRlUk8"
   },
   "source": [
    "**Distance function**\n",
    "An important part of many machine learning methods is the concept of \"distance\" between examples. We often phrase this as a \"metric\" on our inputs. Create a function that takes as input two examples (any two examples, although in this case we will use it with one test and one train), and outputs the distance (we will use Euclidean for now) between them. Although there are many built-in functions the perform this task, please implement your distance function from scratch. However, you are welcome to use numpy functions as part of it (for example, you may use np.sum and similar functions, but look up how they work first).\n",
    "\n",
    "\n",
    "**Quantify the accuracy**\n",
    "Loop through all the filtered test examples, using your classification function to predict the label for each one. Also create a way of determining if the prediction was correct or not, based on the labels of the test data. Compute the fraction or percentage of correctly predicted examples. How does this change as $K$ varies? Try $K$ 1-10 (at least) and record the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EL9XEpUlUk9"
   },
   "source": [
    "## Questions:\n",
    "* What is the accuracy of KNN in the test set for K=1?\n",
    "* What is the accuracy of KNN in the test set for K=2?\n",
    "* What is the accuracy of KNN in the test set for K=3?\n",
    "* ...\n",
    "* What is the accuracy of KNN in the test set for K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Tb96s3lUk9"
   },
   "source": [
    "## In depth questions\n",
    "\n",
    "* Extend your algorithm to a multi-class setting (i.e. distinguish between 3 or more digits). How does this change your best value of K?\n",
    "* If you are familiar with confusion matrices, create one for this test dataset and your “best” value of K.\n",
    "* Create a plot of accuracy vs. K.\n",
    "* Visualize some of the examples that were classified incorrectly. The examples are 16x16 gray-scale images, so you can plot them on a grid.\n",
    "\n",
    "**Analysis Questions**\n",
    "\n",
    "* What values of k did you try?\n",
    "* Which value of k produced the highest accuracy? What general trends did you observe as k increased?\n",
    "* When using the entire training dataset, what are your observations about the runtime of K-nearest neighbors? List 1-2 ideas for making this algorithm faster.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RepMLA_Lab-1_13.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
